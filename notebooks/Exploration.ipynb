{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a562490-f3f3-4e14-8be4-01870f039ef7",
   "metadata": {},
   "source": [
    "# Cyber Security Attacks Model\n",
    "\n",
    "The model is supposed to predict a cyber attack type based on user input.\n",
    "\n",
    "Questions:\n",
    "- What user input? Which fields can they input? Presumably all fields that are going to be used in final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb107cd-81ea-4b3c-bd6e-7a011e4e74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf934dfa-0833-4a85-b2c6-a4f2a5cb2d16",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc5ea1b-eb74-492f-8868-645198a7e5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Source IP Address</th>\n",
       "      <th>Destination IP Address</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Packet Length</th>\n",
       "      <th>Packet Type</th>\n",
       "      <th>Traffic Type</th>\n",
       "      <th>Payload Data</th>\n",
       "      <th>Malware Indicators</th>\n",
       "      <th>Anomaly Scores</th>\n",
       "      <th>Alerts/Warnings</th>\n",
       "      <th>Attack Type</th>\n",
       "      <th>Attack Signature</th>\n",
       "      <th>Action Taken</th>\n",
       "      <th>Severity Level</th>\n",
       "      <th>User Information</th>\n",
       "      <th>Device Information</th>\n",
       "      <th>Network Segment</th>\n",
       "      <th>Geo-location Data</th>\n",
       "      <th>Proxy Information</th>\n",
       "      <th>Firewall Logs</th>\n",
       "      <th>IDS/IPS Alerts</th>\n",
       "      <th>Log Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-30 06:33:58</td>\n",
       "      <td>103.216.15.12</td>\n",
       "      <td>84.9.164.252</td>\n",
       "      <td>31225</td>\n",
       "      <td>17616</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>503</td>\n",
       "      <td>Data</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>Qui natus odio asperiores nam. Optio nobis ius...</td>\n",
       "      <td>IoC Detected</td>\n",
       "      <td>28.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malware</td>\n",
       "      <td>Known Pattern B</td>\n",
       "      <td>Logged</td>\n",
       "      <td>Low</td>\n",
       "      <td>Reyansh Dugal</td>\n",
       "      <td>Mozilla/5.0 (compatible; MSIE 8.0; Windows NT ...</td>\n",
       "      <td>Segment A</td>\n",
       "      <td>Jamshedpur, Sikkim</td>\n",
       "      <td>150.9.97.135</td>\n",
       "      <td>Log Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-26 07:08:30</td>\n",
       "      <td>78.199.217.198</td>\n",
       "      <td>66.191.137.154</td>\n",
       "      <td>17245</td>\n",
       "      <td>48166</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>1174</td>\n",
       "      <td>Data</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>Aperiam quos modi officiis veritatis rem. Omni...</td>\n",
       "      <td>IoC Detected</td>\n",
       "      <td>51.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Malware</td>\n",
       "      <td>Known Pattern A</td>\n",
       "      <td>Blocked</td>\n",
       "      <td>Low</td>\n",
       "      <td>Sumer Rana</td>\n",
       "      <td>Mozilla/5.0 (compatible; MSIE 8.0; Windows NT ...</td>\n",
       "      <td>Segment B</td>\n",
       "      <td>Bilaspur, Nagaland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Log Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Firewall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-13 08:23:25</td>\n",
       "      <td>63.79.210.48</td>\n",
       "      <td>198.219.82.17</td>\n",
       "      <td>16811</td>\n",
       "      <td>53600</td>\n",
       "      <td>UDP</td>\n",
       "      <td>306</td>\n",
       "      <td>Control</td>\n",
       "      <td>HTTP</td>\n",
       "      <td>Perferendis sapiente vitae soluta. Hic delectu...</td>\n",
       "      <td>IoC Detected</td>\n",
       "      <td>87.42</td>\n",
       "      <td>Alert Triggered</td>\n",
       "      <td>DDoS</td>\n",
       "      <td>Known Pattern B</td>\n",
       "      <td>Ignored</td>\n",
       "      <td>Low</td>\n",
       "      <td>Himmat Karpe</td>\n",
       "      <td>Mozilla/5.0 (compatible; MSIE 9.0; Windows NT ...</td>\n",
       "      <td>Segment C</td>\n",
       "      <td>Bokaro, Rajasthan</td>\n",
       "      <td>114.133.48.179</td>\n",
       "      <td>Log Data</td>\n",
       "      <td>Alert Data</td>\n",
       "      <td>Firewall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp Source IP Address Destination IP Address  Source Port  \\\n",
       "0  2023-05-30 06:33:58     103.216.15.12           84.9.164.252        31225   \n",
       "1  2020-08-26 07:08:30    78.199.217.198         66.191.137.154        17245   \n",
       "2  2022-11-13 08:23:25      63.79.210.48          198.219.82.17        16811   \n",
       "\n",
       "   Destination Port Protocol  Packet Length Packet Type Traffic Type  \\\n",
       "0             17616     ICMP            503        Data         HTTP   \n",
       "1             48166     ICMP           1174        Data         HTTP   \n",
       "2             53600      UDP            306     Control         HTTP   \n",
       "\n",
       "                                        Payload Data Malware Indicators  \\\n",
       "0  Qui natus odio asperiores nam. Optio nobis ius...       IoC Detected   \n",
       "1  Aperiam quos modi officiis veritatis rem. Omni...       IoC Detected   \n",
       "2  Perferendis sapiente vitae soluta. Hic delectu...       IoC Detected   \n",
       "\n",
       "   Anomaly Scores  Alerts/Warnings Attack Type Attack Signature Action Taken  \\\n",
       "0           28.67              NaN     Malware  Known Pattern B       Logged   \n",
       "1           51.50              NaN     Malware  Known Pattern A      Blocked   \n",
       "2           87.42  Alert Triggered        DDoS  Known Pattern B      Ignored   \n",
       "\n",
       "  Severity Level User Information  \\\n",
       "0            Low    Reyansh Dugal   \n",
       "1            Low       Sumer Rana   \n",
       "2            Low     Himmat Karpe   \n",
       "\n",
       "                                  Device Information Network Segment  \\\n",
       "0  Mozilla/5.0 (compatible; MSIE 8.0; Windows NT ...       Segment A   \n",
       "1  Mozilla/5.0 (compatible; MSIE 8.0; Windows NT ...       Segment B   \n",
       "2  Mozilla/5.0 (compatible; MSIE 9.0; Windows NT ...       Segment C   \n",
       "\n",
       "    Geo-location Data Proxy Information Firewall Logs IDS/IPS Alerts  \\\n",
       "0  Jamshedpur, Sikkim      150.9.97.135      Log Data            NaN   \n",
       "1  Bilaspur, Nagaland               NaN      Log Data            NaN   \n",
       "2   Bokaro, Rajasthan    114.133.48.179      Log Data     Alert Data   \n",
       "\n",
       "  Log Source  \n",
       "0     Server  \n",
       "1   Firewall  \n",
       "2   Firewall  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\isabela.ribeiro\\Desktop\\cybersecurity_attacks.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18986366-82a0-4a13-82ec-e076b4b62720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'source_ip_address', 'destination_ip_address',\n",
       "       'source_port', 'destination_port', 'protocol', 'packet_length',\n",
       "       'packet_type', 'traffic_type', 'payload_data', 'malware_indicators',\n",
       "       'anomaly_scores', 'alerts_and_warnings', 'attack_type',\n",
       "       'attack_signature', 'action_taken', 'severity_level',\n",
       "       'user_information', 'device_information', 'network_segment',\n",
       "       'geo-location_data', 'proxy_information', 'firewall_logs',\n",
       "       'ids_and_ips_alerts', 'log_source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [x.lower() for x in df.columns]\n",
    "df.columns = df.columns.str.replace('/', \"_and_\")\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26a761-c331-4ebd-8342-f80de12c1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://db-ip.com/db/download/ip-to-country-lite\n",
    "df_geo = pd.read_csv(\"../data/dbip-country-lite-2025-03.csv\", names=['start_ip', 'end_ip', 'country_code'])\n",
    "df_geo = df_geo[df_geo['country_code'].notna()]\n",
    "df_geo = df_geo[~df_geo['start_ip'].str.contains(':')] # removes ipv6 addresses\n",
    "df_geo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75729c4f-8a25-42bd-a602-6a27a818bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asn = pd.read_csv(\"../data/dbip-asn-lite-2025-03.csv\", names=['start_ip', 'end_ip', 'asn_id', 'asn_desc'])\n",
    "df_asn = df_asn[~df_asn['start_ip'].str.contains(':')] # removes ipv6 addresses\n",
    "df_asn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db885857-04ef-45f9-bd3c-f6ca8b76474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ports = pd.read_csv(\"../data/top-30000-most-popular-tcp-ports-nmap-sorted.csv\", header=None)\n",
    "df_ports = pd.melt(df_ports)\n",
    "l_ports = df_ports['value'].tolist()\n",
    "l_ports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9488fd63-e88f-477b-a826-ad6f747e3a29",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b7936-3fee-4d31-a60f-c0a6e911d39c",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "\n",
    "Before exploring the data entirely, there are 4 columns that extra data can be extracted from:\n",
    "- timestamp\n",
    "- source_ip_address\n",
    "- destination_ip_address\n",
    "- device_information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92483d18-6a4b-4f96-91d9-0fee81d172a9",
   "metadata": {},
   "source": [
    "#### Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e369f-cc41-48ce-9b7f-28694c43526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "df['day_of_week'] = pd.to_datetime(df['timestamp']).dt.dayofweek\n",
    "df['month'] = pd.to_datetime(df['timestamp']).dt.month\n",
    "df['quarter'] = pd.to_datetime(df['timestamp']).dt.quarter\n",
    "df['year'] = pd.to_datetime(df['timestamp']).dt.year\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a574f74b-861d-4601-b2d2-7e1412a5309a",
   "metadata": {},
   "source": [
    "#### IP Addresses\n",
    "\n",
    "The 2 IP Address columns can be used to extract more valuable data. According to https://ipinfo.io/blog/ip-address-information, we can get information like location, ISP, network info (ASN and its type - ASN is a block of IPs owned by an org, hostname, number of domains on IP, privacy detection - coming from VPN or proxy).\n",
    "\n",
    "Most of the data is behind a paywall except for the geolocation data. Although, data like ASN and IP addresses known for attacks could be useful.\n",
    "\n",
    "In our case, a downloaded database is used to compare with the help of a package: https://pypi.org/project/ipaddress/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c25288-5a97-4a38-8c39-73bb8f572d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress\n",
    "\n",
    "def ip_to_int(ip_address):\n",
    "    ip_cleaned = '.'.join(str(int(octet)) for octet in ip_address.split('.'))\n",
    "    return int(ipaddress.IPv4Address(ip_cleaned))\n",
    "\n",
    "def is_private(ip_address):\n",
    "    return ipaddress.ip_address(ip_address).is_private\n",
    "\n",
    "for col in ['start_ip', 'end_ip']:\n",
    "    df_geo[f\"{col}_int\"] = df_geo[col].apply(ip_to_int)\n",
    "    df_asn[f\"{col}_int\"] = df_asn[col].apply(ip_to_int)\n",
    "\n",
    "for col in ['source_ip_address', 'destination_ip_address']:\n",
    "    df[f\"{col}_int\"] = df[col].apply(ip_to_int)\n",
    "    df[f\"{col}_is_private\"] = df[col].apply(is_private)\n",
    "    \n",
    "df_geo = df_geo.sort_values('start_ip_int').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f61929-c607-4b40-b12b-499e1fd33525",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_private_ip = df[df['source_ip_address_is_private']==True]\n",
    "print(source_private_ip['source_ip_address_is_private'].value_counts())\n",
    "\n",
    "dest_private_ip = df[df['destination_ip_address_is_private']==True]\n",
    "print(dest_private_ip['destination_ip_address_is_private'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7e592-8a24-4d31-9be3-b575c3e6521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ip_info(info_df, df_info_col, start_ips, end_ips, new_col_suffix):\n",
    "\n",
    "    cummax_ends = np.maximum.accumulate(end_ips)\n",
    "    cummax_indices = np.empty_like(cummax_ends, dtype=np.int64)\n",
    "    cummax_indices[0] = 0\n",
    "    \n",
    "    for i in range(1, len(end_ips)):\n",
    "        if end_ips[i] > cummax_ends[i-1]:\n",
    "            cummax_indices[i] = i\n",
    "        else:\n",
    "            cummax_indices[i] = cummax_indices[i-1]\n",
    "    \n",
    "    for loc in ['source','destination']:\n",
    "        \n",
    "        # this will match all rows all rows with vals from start_ips. there is no upper limit so all rows will be filled.\n",
    "        indeces = np.searchsorted(\n",
    "            cummax_ends,\n",
    "            df[f'{loc}_ip_address_int'].values,\n",
    "            side='left',\n",
    "        )\n",
    "        indeces[indeces == len(end_ips)] = len(end_ips) - 1\n",
    "        ai = cummax_indices[indeces]\n",
    "        # the solution for the above problem is to create a mask where False will be given if it does not fit with the end_ip too.\n",
    "        mask = (df[f'{loc}_ip_address_int'].values >= start_ips[ai]) & (df[f'{loc}_ip_address_int'].values <= end_ips[ai])\n",
    "            \n",
    "        matched_values = np.where(mask, info_df[df_info_col].values[ai], np.nan)\n",
    "        df[f'{loc}_{new_col_suffix}'] = matched_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab7288-b0a4-43d3-bc0a-25f28870e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_start_ips = df_geo['start_ip_int'].values\n",
    "geo_end_ips = df_geo['end_ip_int'].values\n",
    "add_ip_info(df_geo, 'country_code', geo_start_ips, geo_end_ips, 'country')\n",
    "\n",
    "asn_start_ips = df_asn['start_ip_int'].values\n",
    "asn_end_ips = df_asn['end_ip_int'].values\n",
    "add_ip_info(df_asn, 'asn_id', asn_start_ips, asn_end_ips, 'asn_id')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774eacf4-7703-4ead-a00d-c42bee977645",
   "metadata": {},
   "source": [
    "#### Device Information\n",
    "\n",
    "The values in this column has information in the form of user agents. We can extract info like browser, operating system, device model, etc.\n",
    "\n",
    "Something to keep in mind is that data this type of data can be easily faked but can still point towards an anomaly.\n",
    "\n",
    "There is Python package that can parse this data: https://pypi.org/project/user-agents/\n",
    "\n",
    "Initially, the data inlcuded versions for each type making the data very specific and the column values were too broad.\n",
    "Browser accrued 5490 results\n",
    "OS accrued 174 results. While more manageable, the data within the versions seemed to be evenly spread within each OS family.\n",
    "Device accrued only 8 device types - most types were Apple based, but the type \"Other None None\" was more than half of the dataset.ie. > 20000.\n",
    "This can skew the dataset but it might be useful to group the Apple devices and use Other None None as another category.\n",
    "\n",
    "To regenerate the data as described above, you can use the following code:\n",
    "```\n",
    "df = df.assign(**{\"Browser\": df[\"Device Information\"].apply(lambda x : parse(x).browser.family + \" \" + parse(x).browser.version_string)})\n",
    "df = df.assign(**{\"OS\": df[\"Device Information\"].apply(lambda x : parse(x).os.family + \" \" + parse(x).os.version_string)})\n",
    "df = df.assign(**{'Device': df['Device Information'].apply(lambda x : str(parse(x).device.family) + \" \" + str(parse(x).device.brand) + \" \" + str(parse(x).device.model))})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670dc88-bc5b-4571-b3af-42678110afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from user_agents import parse\n",
    "\n",
    "df = df.assign(browser=df['device_information'].apply(lambda x : parse(x).browser.family))\n",
    "df = df.assign(os=df['device_information'].apply(lambda x : parse(x).os.family))\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894716f9-34aa-4049-8052-7504eaa69ae4",
   "metadata": {},
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94b546-37a8-4e55-860b-e558ad2b4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd3b38-3cb3-4da5-b213-49a26ecc6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf68814-4f5e-48b1-9a0b-b90dd436feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = df.duplicated()\n",
    "dups[dups == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0e1e2-a8c9-4cba-b4d6-23797c951a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078e2df-085e-4da3-8abb-9b7177dc52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusable function\n",
    "def show_nulls():\n",
    "    null_count = df.isna().sum()\n",
    "    print(null_count[null_count > 0])\n",
    "\n",
    "show_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f919ca7-6335-4e7f-83d4-895dae07e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e863b-f137-4611-a2f2-9c5fe830f65d",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning\n",
    "\n",
    "Columns that immediately stand out as unnecessary are the ones that were used to extract data:\n",
    "- timestamp\n",
    "- source_ip_address\n",
    "- destination_ip_address\n",
    "- device_information\n",
    "\n",
    "Then the columns that aren't as useful, especially those with a high value count that are hard to classify such as:\n",
    "- user_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c61954-268a-4e43-81ec-1272ca2588e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'timestamp', 'source_ip_address', 'source_ip_address_int', 'destination_ip_address',\n",
    "    'destination_ip_address_int', 'device_information', 'user_information'\n",
    "]\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eccc22-6cca-4f34-b6dd-66f7b5f1b514",
   "metadata": {},
   "source": [
    "## Analysis (almost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f98c6e-eeb2-4cd1-9bf9-2bf620bfe94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c723e-8f30-49bf-924e-d862604811cd",
   "metadata": {},
   "source": [
    "From the raw stats shown previously, we can determine the following:\n",
    "- No duplicated rows.\n",
    "\n",
    "**Need Clarity**\n",
    "\n",
    "- From whose perspective is the data from? The victim?\n",
    "- Is timestamp using UTC time or some other uniform time zone?\n",
    "- Is the action_taken column showing actions done by the system after the attack happened and before human intervention?\n",
    "\n",
    "**Further Analysis**\n",
    "\n",
    "- Are countries relevant? Because we don't know if the data collection is concentrated in a certain area. Model results can be skewed.\n",
    "- Ports above a certain value can be used for anything unlike the ports below that threshold. Can we assume that the ports selected are randomly assigned by the attacker?\n",
    "- Packet Type has some relation to Protocol. Do some more checks to make sure.\n",
    "- Checks on Packet Length.\n",
    "- Checks on payload_data to see if there are any patterns within them. It looks like irrelevant latin text - possibly auto-generated.\n",
    "- Check which values from some other column are paired with Malware Indicators.\n",
    "- What is the Anomaly Score? Not sure which part of the process it is in. How does it relate to Attack Signatures?\n",
    "- Can we group the different types of alerts? Or do they specifically indicate which type of attack there is. Or can we group them into a single column where the value will be true once 1 of the alert columns has a True value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a081b-ad40-449b-b6dd-4f9f65f1c126",
   "metadata": {},
   "source": [
    "### Device Information\n",
    "\n",
    "Upon further analysis:\n",
    "- another column can be created for to see if the device is a mobile or not (bool).\n",
    "  - before the next step, look for discrepancies between os and browser type since we know that the data can be faked.\n",
    "- the browser column can be simplified by grouping the browsers together like \"Chrome\" and \"Chrome Mobile iOS\" as one family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac63106-3f9a-4fa8-ba84-822c429812cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['os'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa684cc1-bf61-4e26-b9fa-0a683e0ed190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['browser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c46292-c32f-4722-88bf-9d6798be8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "browsers = df['browser'].unique()\n",
    "\n",
    "def is_mobile_browser(browser_name):\n",
    "    return any(c.isspace() for c in browser_name)\n",
    "\n",
    "browser_families = [x for x in browsers if not is_mobile_browser(x)]\n",
    "\n",
    "def is_mobile_os(os_name):\n",
    "    mobile_os = [\"iOS\", \"Android\"]\n",
    "    return any(os_name in x for x in mobile_os)\n",
    "\n",
    "def get_browser_family(browser_name):\n",
    "    if is_mobile_browser(browser_name):\n",
    "        for family in browser_families:\n",
    "            if family in browser_name:\n",
    "                return family\n",
    "    else:\n",
    "        return browser_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef44522-1009-4aac-a68e-9094474bd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(is_mobile=df['os'].apply(is_mobile_os))\n",
    "df = df.assign(is_mobile_browser=df['browser'].apply(is_mobile_browser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde157c-59f0-4d2c-bdb0-52ad5d1077fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking all browsers linked to mobile devices\n",
    "df_mobile = df[df['is_mobile']==True]\n",
    "df_mobile['browser'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c2d72-33e6-4631-8dab-c1b5e646ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(df['is_mobile'], df['is_mobile_browser'])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.heatmap(contingency_table, annot=True, cmap='Blues', fmt='g', cbar_kws={'label':\"Count\"})\n",
    "plt.title(\"Heatmap of Mobile and Browser Combinations\")\n",
    "plt.xlabel(\"Is Mobile Browser\")\n",
    "plt.ylabel(\"Is Mobile\")\n",
    "plt.xticks([0.5, 1.5], [\"No\", \"Yes\"], rotation=0)\n",
    "plt.yticks([0.5, 1.5], [\"No\", \"Yes\"], rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55468c1-f0a6-4c96-9dc4-3107e34a9378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is done here because this change would affect the results of the cell checking for browsers linked to mobile\n",
    "# the goal of the previous cell is to see if there are any non-mobile browsers\n",
    "df['browser'] = df['browser'].apply(get_browser_family)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781acb03-c448-4b3f-b565-c7af6fa19537",
   "metadata": {},
   "source": [
    "### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d646e-d259-425d-a275-ca3224a72724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_vals():\n",
    "    values_unique = df.nunique()\n",
    "    categorical_possible = values_unique[values_unique < 10]\n",
    "    \n",
    "    for col_name, val_count in categorical_possible.items():\n",
    "        msg = \"\"\n",
    "        col_unique_vals = df[col_name].unique()\n",
    "        \n",
    "        if val_count == 1:\n",
    "            col_unique_vals = [x for x in col_unique_vals if not pd.isnull(x)]\n",
    "            msg = \"Removed null value. Possible boolean?\"\n",
    "            \n",
    "        print(f\"{col_name}, Values: {col_unique_vals} {msg}\")\n",
    "\n",
    "get_categorical_vals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e253e-8e21-4896-9030-271153894be3",
   "metadata": {},
   "source": [
    "From the data generated above, we can see that some columns have few unique values. These values can indicate categories and therefore, they can be encoded making it easier for the algorithms to understand.\n",
    "Both ordinal and nominal encoding should be considered.\n",
    "\n",
    "Possible fields for ordinal encoding: severity_level\n",
    "\n",
    "In addition that that, there are columns that contain only 1 unique value; usually the single value and others are populated by null values. Those columns can be possibly used as booleans. proxy_information is another good contender for a boolean since we won't need the exact values but rather if a proxy was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999858a-6ce3-4d99-ab67-89c55e38aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_proxy'] = np.where(df['proxy_information'].notnull(), True, False)\n",
    "df['has_malware_indicator'] = np.where(df['malware_indicators'].notnull(), True, False)\n",
    "df['has_alerts_and_warnings'] = np.where(df['alerts_and_warnings'].notnull(), True, False)\n",
    "df['has_firewall_log'] = np.where(df['firewall_logs'].notnull(), True, False)\n",
    "df['has_ids_ips_alert'] = np.where(df['ids_and_ips_alerts'].notnull(), True, False)\n",
    "\n",
    "# drop original\n",
    "columns_to_drop = ['malware_indicators', 'alerts_and_warnings', 'proxy_information', 'firewall_logs', 'ids_and_ips_alerts']\n",
    "df.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "show_nulls()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270e014b-bbab-4a21-9398-4bab1d77cbc4",
   "metadata": {},
   "source": [
    "We can see that 4 out of the 5 new bools are related to alerts so a new column can be created to concat them - if at least 1 is true, then the new column, has_system_alert, will be true.\n",
    "Additionally, we can get an count of all alerts into a new column, alert_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd165395-a8b4-4a4b-a443-74d9e794b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_system_alert(row):\n",
    "    return True if row['has_malware_indicator'] or row['has_alerts_and_warnings'] or row['has_firewall_log'] or row['has_ids_ips_alert'] else False\n",
    "\n",
    "def count_alerts(row):\n",
    "    count = 0\n",
    "\n",
    "    if row['has_malware_indicator']:\n",
    "        count+=1\n",
    "    if row['has_alerts_and_warnings']:\n",
    "        count+=1\n",
    "    if row['has_firewall_log']:\n",
    "        count+=1\n",
    "    if row['has_ids_ips_alert']:\n",
    "        count+=1\n",
    "        \n",
    "    return count\n",
    "    \n",
    "df['has_system_alert'] = df.apply(has_system_alert, axis=1)\n",
    "df['alert_count'] = df.apply(count_alerts, axis=1)\n",
    "\n",
    "print(df['has_system_alert'].value_counts())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b9c2a-190f-4a89-8ca5-7b0704a2398e",
   "metadata": {},
   "source": [
    "Well... based on the value_counts on has_system_alert, it looks useless, lol."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941452a-3259-4ab5-b2bb-84a3bb5e354a",
   "metadata": {},
   "source": [
    "### Networking Stuff\n",
    "\n",
    "The columns: protocol, packet_length, packet_type, traffic_type, payload_data can be combined somehow to create one or a few new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e416c-3f24-44f6-80fd-f00025aee7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in ['source', 'destination']:\n",
    "    df[f'{loc}_port_bin'] = df[f'{loc}_port'].apply(\n",
    "        lambda value: \"registered\" if 1024 <= value <= 49151 else \"dynamic\"\n",
    "    )\n",
    "\n",
    "df['packet_length_bin'] = df['packet_length'].apply(\n",
    "    lambda x: \"small\" if x <= 256 else\n",
    "    \"medium\" if x <= 512 else\n",
    "    \"large\" if x <= 1024 else\n",
    "    \"very large\"\n",
    ")\n",
    "\n",
    "df['packet_length_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59b414-aebc-4874-83b4-404a0d3c43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_popular_port(port):\n",
    "    return True if port in l_ports else False\n",
    "\n",
    "df['is_popular_source_port'] = df['source_port'].apply(is_popular_port)\n",
    "df['is_popular_destination_port'] = df['destination_port'].apply(is_popular_port)\n",
    "df['protocol_uses_ports'] = df['protocol'].apply(lambda x : '0' if x == 'ICMP' else '1') # TODO: check feature crossing with bool\n",
    "\n",
    "print(df['is_popular_source_port'].value_counts())\n",
    "print(df['is_popular_destination_port'].value_counts())\n",
    "print(df['protocol_uses_ports'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81015547-e000-4e9c-a5c0-254629b658e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['protocol_packet_type'] = df[['protocol', 'packet_type']].apply('_'.join, axis=1)\n",
    "df['protocol_traffic_type'] = df[['protocol', 'packet_type']].apply('_'.join, axis=1)\n",
    "df['source_port_bin__uses_port'] = df[['source_port_bin', 'protocol_uses_ports']].apply('_'.join, axis=1)\n",
    "df['destination_port_bin__uses_port'] = df[['destination_port_bin', 'protocol_uses_ports']].apply('_'.join, axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ac97f7-2371-476f-97b7-edd88a3a825b",
   "metadata": {},
   "source": [
    "### Payload Data\n",
    "\n",
    "The data could contain signs of an attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca3cbf-3b6c-4ed4-bf69-bfd6dc991fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['payload_data'].tolist()[10000:10010]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1acc2-01e8-4b80-bd02-3beb53292f9d",
   "metadata": {},
   "source": [
    "### ASN & Countries\n",
    "\n",
    "There is missing data in the countries and asn columns. Investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071702e0-1c3f-457a-8d54-e3ca81fb3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_nulls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0513c7-8292-421a-8b16-eab6dc34f00a",
   "metadata": {},
   "source": [
    "Since less than 10 countries are empty and about 15% ASN is empty, we can fill them with the modal value just to ensure the columns are filled for future tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403b29c-fa3d-40ff-9efa-7f2a4d8622f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_country'].fillna(df['source_country'].mode()[0], inplace=True)\n",
    "df['destination_country'].fillna(df['destination_country'].mode()[0], inplace=True)\n",
    "df['source_asn_id'].fillna(df['source_asn_id'].mode()[0], inplace=True)\n",
    "df['destination_asn_id'].fillna(df['destination_asn_id'].mode()[0], inplace=True)\n",
    "show_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848e8a1-0f78-41a3-98a2-2b2b9b4f1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ASN IDs are supposed to be int rather than float\n",
    "df['source_asn_id'] = df['source_asn_id'].astype(np.int64)\n",
    "df['destination_asn_id'] = df['destination_asn_id'].astype(np.int64)\n",
    "print(df.source_asn_id.dtype)\n",
    "print(df.destination_asn_id.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fdfca-9443-4324-bcc5-6af72d7898a4",
   "metadata": {},
   "source": [
    "### Class Distribution (for target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2476ed-63f2-4be8-a813-b6c05bc8afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x=df['attack_type'])\n",
    "plt.title('Attack Type Distribution')\n",
    "plt.xlabel('Attack Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734797c7-c8e6-4ef7-856d-69bd36c1b170",
   "metadata": {},
   "source": [
    "The graph above shows that the target variables are uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94bb586-b7db-41a5-beeb-bcb98434081e",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00f310-8767-4866-b37d-e801f64d6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bdc9d-86a4-498f-9119-ebd32bc5f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_categorical_vals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead7945-6575-4a69-97cf-09976f7d2642",
   "metadata": {},
   "source": [
    "### Some Preprocessing - Encoding\n",
    "For now, only columns that can be ordinally encoded will be encoded.\n",
    "\n",
    "The one that stands out is severity_level. Maybeee action_taken can be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3136f-e67a-4e91-a314-bb8aa41bc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "order = ['Low', 'Medium', 'High']\n",
    "oe = OrdinalEncoder(categories=[order])\n",
    "df['severity_level']= oe.fit_transform(df[['severity_level']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c420d303-5ec6-45b4-9069-ae4de452fafe",
   "metadata": {},
   "source": [
    "### Feature Correlation with Attack Type\n",
    "\n",
    "We can check categorical using chi squared, then numerical using...\n",
    "\n",
    "\"The Chi-square test is a statistical test that is used to determine whether there is a significant difference between the observed frequency of a categorical variable and the expected frequency based on the assumption of independence. It can be used to select the best categorical features for a classification model.\"\n",
    "From: https://datascience.stackexchange.com/questions/117287/are-chi-square-and-anova-f-classif-to-select-best-features\n",
    "\n",
    "\"The Chi-Square test determines whether there is a significant association between two categorical variables. It helps in hypothesis testing to check whether observed frequencies differ from expected ones.\"\n",
    "\"If the p-value is less than the significance level (typically 0.05), reject the null hypothesis, indicating a significant relationship between the variables.\n",
    "If the p-value is greater than 0.05, fail to reject the null hypothesis, meaning no significant relationship was found.\"\n",
    "From: https://www.simplilearn.com/tutorials/statistics-tutorial/chi-square-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27c7698-711e-47ff-bae7-194461650aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'protocol', 'packet_type', 'traffic_type', 'attack_signature', 'action_taken',\n",
    "    'severity_level', 'network_segment', 'log_source', 'hour',\n",
    "    'day_of_week', 'quarter', 'source_ip_address_is_private', 'destination_ip_address_is_private',\n",
    "    'source_country', 'destination_country', 'source_asn_id', 'destination_asn_id', 'browser',\n",
    "    'os', 'is_mobile', 'is_mobile_browser', 'has_malware_indicator', 'has_alerts_and_warnings',\n",
    "    'has_proxy', 'has_firewall_log', 'has_ids_ips_alert', 'has_system_alert'\n",
    "]\n",
    "\n",
    "numeric_features = ['source_port', 'destination_port', 'packet_length','anomaly_scores', 'alert_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c825d11-d756-4627-8059-9564f9bee5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(feature):\n",
    "    contingency_table = pd.crosstab(df[feature], df['attack_type'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    return feature, chi2, p\n",
    "\n",
    "chi_square_results = [chi_square_test(feature) for feature in categorical_features]\n",
    "\n",
    "chi_square_df = pd.DataFrame(chi_square_results, columns=['feature', 'chi2', 'p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e8a3f-98a1-4c08-9270-53347e0ca47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "plt.figure(figsize=(20,10))\n",
    "chi2_df = chi_square_df.sort_values(by='chi2', ascending=False)\n",
    "pv_df = chi_square_df.sort_values(by='p', ascending=True) \n",
    "chi2_df.plot.bar(x='feature', y='chi2', figsize=(10,5), ax=axs[0])\n",
    "pv_df.plot.bar(x='feature', y='p', ax=axs[1])\n",
    "\n",
    "# features with p-values < 0.05 are statistically significant\n",
    "chi_square_df[chi_square_df['p'] < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbcaf6-5f46-43d6-a18b-f5a64545efd4",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In test stages only. Just to see what happens. Not meant to produce a usable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725b319-7b4b-4f68-86c3-4486775b9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cols_model = [\n",
    "    'attack_type', 'packet_type', 'browser', 'is_mobile_browser', 'is_mobile', 'os', 'protocol', 'attack_signature'\n",
    "]\n",
    "df_model = df[cols_model]\n",
    "\n",
    "X_no_encode = df_model.drop(columns=['attack_type'])\n",
    "\n",
    "ohe=OneHotEncoder(sparse_output=False, handle_unknown='error')\n",
    "X_encoded = ohe.fit_transform(X_no_encode)\n",
    "\n",
    "categorical_columns = [f'{col}_{cat}' for i, col in enumerate(X_no_encode.columns) for cat in ohe.categories_[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee22de-3242-4849-bb11-857eee3084b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = pd.DataFrame(X_encoded, columns=categorical_columns)\n",
    "y = df_model['attack_type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786fd07-106e-4254-9592-17c6ca0c1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69299b32-dd49-4d45-a697-5a613689470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
    "forest_importances = pd.Series(importances, index=categorical_columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e0d75bd-5858-4593-b9a2-677228e19e03",
   "metadata": {},
   "source": [
    "ISABELA EDITING 18/03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdb2f2-beec-42dc-a48d-0389f3fe9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ports with something else\n",
    "df['source_port_anomaly'] = df[['source_port_bin__uses_port', 'Anomaly Score']].apply('_'.join, axis=1)\n",
    "df['dest_port_anomaly'] = df[['destination_port_bin__uses_port', 'Anomaly Score']].apply('_'.join, axis=1)\n",
    "\n",
    "df['source_port_action'] = df[['source_port_bin__uses_port', 'Action Taken']].apply('_'.join, axis=1)\n",
    "df['dest_port_action'] = df[['destination_port_bin__uses_port', 'Action Taken']].apply('_'.join, axis=1)         \n",
    "\n",
    "df['source_port_traf_type'] = df[['source_port_bin__uses_port', 'Traffic Type']].apply('_'.join, axis=1)\n",
    "df['dest_port_traf_type'] = df[['destination_port_bin__uses_port', 'Traffic Type']].apply('_'.join, axis=1)\n",
    "\n",
    "#Packet Lenght with something else\n",
    "df['pckt_len_traf_tp'] = df[['Packet Lenght', 'Traffic Type']].apply('_'.join, axis=1)\n",
    "df['pckt_len_pckt_tp'] = df[['Packet Lenght', 'Packet Type']].apply('_'.join, axis=1)\n",
    "df['pckt_len_Protocol'] = df[['Packet Lenght', 'Protocol']].apply('_'.join, axis=1)\n",
    "df['pckt_len_Source'] = df[['Packet Lenght', 'Log Source']].apply('_'.join, axis=1)\n",
    "\n",
    "#Packet Type with something else\n",
    "df['pckt_tp_Protocol'] = df[['Packet Type', 'Protocol']].apply('_'.join, axis=1)\n",
    "df['pckt_tp_Source'] = df[['Packet Type', 'Log Source']].apply('_'.join, axis=1)\n",
    "df['pckt_tp_anomaly'] = df[['Packet Type', 'Anomaly Score']].apply('_'.join, axis=1)\n",
    "\n",
    "#Coutries\n",
    "df['source_country_destination'] = df[['source_country', 'destination_country']].apply('_'.join, axis=1)\n",
    "\n",
    "#Traffic Type with something else\n",
    "df['trf_tp_anomaly'] = df[['Anomaly Score', 'Protocol']].apply('_'.join, axis=1)\n",
    "df['trf_tp_protocol'] = df[['Traffic Type', 'Protocol']].apply('_'.join, axis=1)                           \n",
    "\n",
    "#Crossing new columns with itselves\n",
    "# df['trf_tp_protocol'] = df[['protocol_uses_ports', 'Protocol']].apply('_'.join, axis=1) \n",
    "# I guess you created this one but I'm not sure, I'll considere \"protocol_uses_ports\". If is wrong, I need to switch later\n",
    "\n",
    "#protocol_uses_ports \n",
    "df['trf_tp_protocol_source_port_action'] = df[['trf_tp_protocol', 'source_port_action']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_dest_port_action'] = df[['trf_tp_protocol', 'dest_port_action']].apply('_'.join, axis=1) \n",
    "\n",
    "df['trf_tp_protocol_source_port_action_alert_warning'] = df[['trf_tp_protocol_source_port_action', 'Alert/Warning']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_dest_port_action_alert_warning'] = df[['trf_tp_protocol_dest_port_action', 'Alert/Warning']].apply('_'.join, axis=1) \n",
    "\n",
    "df['trf_tp_protocol_source_port_action_alert_warning_firewall'] = df[['trf_tp_protocol_source_port_action_alert_warning', 'Firewall Alert']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_dest_port_action_alert_warning_firewall'] = df[['trf_tp_protocol_dest_port_action_alert_warning', 'Firewall Alert']].apply('_'.join, axis=1) \n",
    "\n",
    "df['trf_tp_protocol_source_port_action_alert_warning_firewall_IOC'] = df[['trf_tp_protocol_source_port_action_alert_warning_firewall', 'Malware Alert']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_dest_port_action_alert_warning_firewall_IOC'] = df[['trf_tp_protocol_dest_port_action_alert_warning_firewall', 'Malware Alert']].apply('_'.join, axis=1) \n",
    "\n",
    "df['trf_tp_protocol_source_port_action_alert_warning_firewall_IOC'] = df[['trf_tp_protocol_source_port_action_alert_warning_firewall_IOC', 'Action Taken']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_dest_port_action_alert_warning_firewall_IOC'] = df[['trf_tp_protocol_dest_port_action_alert_warning_firewall_IOC', 'Action Taken']].apply('_'.join, axis=1) \n",
    "\n",
    "df['pckt_tp_anomaly_pckt_tp'] = df[['pckt_tp_anomaly', 'Packet Type']].apply('_'.join, axis=1) \n",
    "\n",
    "#trf_tp_protocol \n",
    "df['trf_tp_protocol_anomaly'] = df[['trf_tp_protocol', 'Anomaly Score']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_pckt_tp'] = df[['trf_tp_protocol', 'Packet Type']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_traf_tp'] = df[['trf_tp_protocol', 'Traffic Type']].apply('_'.join, axis=1) \n",
    "df['trf_tp_protocol_Sever_lv'] = df[['trf_tp_protocol', 'Severity Level']].apply('_'.join, axis=1) \n",
    "\n",
    "#\n",
    "df['trf_tp_protocol_source_port_action_ids'] = df[['trf_tp_protocol_source_port_action', 'IDS/IPS Alert']].apply('_'.join, axis=1)\n",
    "df['trf_tp_protocol_dest_port_action_ids'] = df[['trf_tp_protocol_dest_port_action', 'IDS/IPS Alert']].apply('_'.join, axis=1)\n",
    "\n",
    "df['trf_tp_protocol_source_port_action_ids_pckt_ln'] = df[['trf_tp_protocol_source_port_action_ids', 'Packet Lenght']].apply('_'.join, axis=1)\n",
    "df['trf_tp_protocol_dest_port_action_ids_pckt-ln'] = df[['trf_tp_protocol_dest_port_action_ids', 'Packet Lenght']].apply('_'.join, axis=1\n",
    "\n",
    "df['source_country_destination_proxy'] = df[['source_country_destination', 'Proxy Hidden']].apply('_'.join, axis=1)  ##need to create with you didn't                                                                                                                       \n",
    "\n",
    "df['pckt_tp_Source_traf_tp'] = df[['Traffic Type', 'pckt_tp_Source']].apply('_'.join, axis=1)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
